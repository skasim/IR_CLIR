{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c07267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from clir_files.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.0.0-rc.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import import_ipynb\n",
    "import hi2en_transliterator as transliterator\n",
    "import clir_files as files\n",
    "import googletrans\n",
    "googletrans.__version__ # must be '4.0.0-rc.1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6202cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated(src=en, dest=hi, text=लोग कोरोनवायरस से कैसे मरते हैं, pronunciation=log koronavaayaras se kaise marate hain, extra_data=\"{'confiden...\")\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "hi = translator.translate('how do people die from the coronavirus', src='en', dest=\"hi\")\n",
    "print(hi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717481ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "लाल ('red', 0.6013444066047668)\n",
      "गैरी ('mcnaney', 0.5269891619682312)\n",
      "मकान ('cottage', 0.5818758606910706)\n",
      "मंदिर ('temple', 0.6957460045814514)\n",
      "सागरतट ('coastline', 0.5641415119171143)\n",
      "गाना ('song', 0.7094157934188843)\n",
      "सेब ('cherries', 0.4921698272228241)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "import gensim\n",
    "\n",
    "hin2eng = gensim.models.KeyedVectors.load_word2vec_format('embeddings/hi_mapped.emb')\n",
    "eng2hin = gensim.models.KeyedVectors.load_word2vec_format('embeddings/en_mapped.emb')\n",
    "\n",
    "for word in ['लाल', 'गैरी', 'मकान', 'मंदिर', 'सागरतट', 'गाना', 'सेब']:\n",
    "    print (\"%s %s\" % (word, eng2hin.similar_by_vector(hin2eng[word])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72559949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('song', 0.7094157934188843),\n",
       " ('sing', 0.6309351325035095),\n",
       " ('songs', 0.6263952255249023),\n",
       " ('tune', 0.6037591099739075),\n",
       " ('singing', 0.5932566523551941),\n",
       " ('singin', 0.590872585773468),\n",
       " ('album', 0.5890897512435913),\n",
       " ('sings', 0.5883166790008545),\n",
       " ('duet', 0.5788858532905579),\n",
       " ('rendition', 0.5718907713890076)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng2hin.similar_by_vector(hin2eng[\"गाना\"])[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcbed050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'koronavaers'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transliterator.transliterate(\"कोरोनावाइरस\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f205cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_emb = gensim.models.KeyedVectors.load_word2vec_format(\"embeddings/wiki.hi.align.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0311eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion(words, emb):\n",
    "    expanded_words = []\n",
    "    for word in words:\n",
    "        similar_words = emb.similar_by_vector(word)[:3]\n",
    "        for sw in similar_words:\n",
    "            if sw[0] not in words:\n",
    "                expanded_words.append(sw[0])\n",
    "    return words + expanded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a100a89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['मकान', 'मकानी', 'मकानो', 'मकानों']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion([\"मकान\"], hi_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1c73af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coxsackievirus', 'polerovirus', 'erbovirus']\n",
      "['coxsackievirus']\n"
     ]
    }
   ],
   "source": [
    "def emb_hi2en(word, num_synonyms=3):\n",
    "    words = eng2hin.similar_by_vector(hin2eng[word])[:num_synonyms]\n",
    "    return [word[0] for word in words]\n",
    "\n",
    "print(emb_hi2en(\"कोरोनावाइरस\"))\n",
    "print(emb_hi2en(\"कोरोनावाइरस\", num_synonyms=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "639c1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    \"\"\"\n",
    "    Reads file.\n",
    "    Parameters:\n",
    "        file_name (str): The filename for file to be read.\n",
    "    Returns:\n",
    "        content (str): contents of the file.\n",
    "    \"\"\"\n",
    "    with open(file_name) as file:\n",
    "        content = file.read()\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d08bf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_remove_doc_id(doc):\n",
    "    \"\"\"\n",
    "    Utilize regex to capture document id and remove document id from the text, so that it is not processed.\n",
    "    Parameters:\n",
    "        doc (str): A string.\n",
    "    Returns:\n",
    "        doc_id (str): The document id.\n",
    "        modified_doc (str): Document with the pattern <p id = xx> removed.\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = r\"<Q ID=\\d+>\"\n",
    "    doc_id = re.findall(r\"\\d+\", doc)\n",
    "    modified_doc = re.sub(pattern, \"\", doc).strip(\"\\n\")\n",
    "    return doc_id[0], (re.sub(\" +\", \" \", modified_doc)).strip()\n",
    "\n",
    "assert capture_and_remove_doc_id(\"99 bottles on the wall\")[1] == \"99 bottles on the wall\"\n",
    "assert capture_and_remove_doc_id(\"<Q ID=2> 99 bottles on the wall\")[0][0] == \"2\"\n",
    "assert capture_and_remove_doc_id(\"<Q ID=2> 99 bottles on the wall\")[1] == \"99 bottles on the wall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b3d50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_queries_from_src_to_dest_lang(infile, outfile, src, dest, conv_type):\n",
    "    \"\"\"\n",
    "    Given the query filename, process and tokenize query terms in the exact same manner as the documents.\n",
    "    Attributes:\n",
    "        filename (str): Filename for the query file.\n",
    "    Returns:\n",
    "        queries (dict(int, list[str])): Return a dict for which the key is an int value representing query_id and \n",
    "        value is a list of strings representing the terms for that query.\n",
    "    \"\"\"\n",
    "    content = read_file(infile)\n",
    "    content = re.split(\"</Q>\", content)\n",
    "    queries_processed = 0\n",
    "    queries = {}\n",
    "    translator = Translator()\n",
    "    \n",
    "    with open(outfile, \"a\") as of:\n",
    "        for query in content:\n",
    "            validation_check = re.findall(r\"\\d+\", query)\n",
    "            try:\n",
    "                validation_check[0]\n",
    "                query_id, query = capture_and_remove_doc_id(query)\n",
    "                if conv_type == \"gt\":\n",
    "                    en_query = translator.translate(query, src=src, dest=dest).text\n",
    "                elif conv_type == \"emb\":\n",
    "                    hi_query = query.split()\n",
    "                    en_query = \"\"\n",
    "                    for word in hi_query:\n",
    "                        try:\n",
    "                            en_query += f\" {emb_hi2en(word, num_synonyms=1)}\"\n",
    "                        except KeyError:\n",
    "                            en_query += f\" {transliterator.transliterate(word)}\"\n",
    "                elif conv_type == \"emb_synset\":\n",
    "                    hi_query = query.split()\n",
    "                    try:\n",
    "                        hi_query = query_expansion(hi_query, hi_emb)\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    en_query = \"\"\n",
    "                    for word in hi_query:\n",
    "                        try:\n",
    "                            for w in emb_hi2en(word):\n",
    "                                en_query+= f\" {w}\"\n",
    "                        except KeyError:\n",
    "                            en_query += f\" {transliterator.transliterate(word)}\"   \n",
    "                elif conv_type == \"emb_no_oov\":\n",
    "                    hi_query = query.split()\n",
    "                    en_query = \"\"\n",
    "                    for word in hi_query:\n",
    "                        try:\n",
    "                            for w in emb_hi2en(word):\n",
    "                                en_query+= f\" {w}\"\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "                elif conv_type == \"gt_emb_synset_translit\":\n",
    "                    en_query = translator.translate(query, src=src, dest=dest).text\n",
    "                    hi_query = query.split()\n",
    "                    try:\n",
    "                        hi_query = query_expansion(hi_query, hi_emb)\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    for word in hi_query:\n",
    "                        try:\n",
    "                            translation = emb_hi2en(word)\n",
    "                            for w in translation:\n",
    "                                if w not in en_query:\n",
    "                                    en_query+= f\" {w}\"\n",
    "                        except KeyError:\n",
    "                            transliteration = transliterator.transliterate(word)\n",
    "                            if transliteration not in en_query:\n",
    "                                en_query += f\" {transliteration}\"\n",
    "                of.write(f\"<Q ID={query_id}>\\n{en_query.strip()}\\n</Q>\\n\\n\")\n",
    "                queries_processed += 1\n",
    "            except IndexError:\n",
    "                pass \n",
    "    print(f\"translated {queries_processed} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9741bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/hi/parsed/cord19.topics.keyword.hi2eng.gt.txt', 'gt']\n",
      "translated 50 queries\n",
      "['data/hi/parsed/cord19.topics.keyword.hi2eng.emb.txt', 'emb']\n",
      "translated 50 queries\n",
      "['data/hi/parsed/cord19.topics.keyword.hi2eng.emb_synset.txt', 'emb_synset']\n",
      "translated 50 queries\n",
      "['data/hi/parsed/cord19.topics.keyword.hi2eng.emb_no_oov.txt', 'emb_no_oov']\n",
      "translated 50 queries\n",
      "['data/hi/parsed/cord19.topics.keyword.hi2eng.gt.emb.synset.translit.txt', 'gt_emb_synset_translit']\n",
      "translated 50 queries\n"
     ]
    }
   ],
   "source": [
    "# keywords\n",
    "infile = files.cord19_topics_keyword_HINDI\n",
    "outfiles = [[files.cord19_topics_keyword_HIN2ENG_GT, \"gt\"], \n",
    "            [files.cord19_topics_keyword_HIN2ENG_EMB, \"emb\"], [files.cord19_topics_keyword_HIN2ENG_EMB_SYNSET, \"emb_synset\"],\n",
    "           [files.cord19_topics_keyword_HIN2ENG_EMB_NO_OOV, \"emb_no_oov\"], \n",
    "            [files.cord19_topics_keyword_HIN2ENG_GT_EMB_SYNSET_TRANSLIT, \"gt_emb_synset_translit\"]]\n",
    "for ofile in outfiles:\n",
    "    print(ofile)\n",
    "    convert_queries_from_src_to_dest_lang(infile, ofile[0], src=\"hi\", dest=\"en\", conv_type=ofile[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93f0781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/hi/parsed/cord19.topics.question.hi2eng.gt.txt', 'gt']\n",
      "translated 50 queries\n",
      "['data/hi/parsed/cord19.topics.question.hi2eng.emb.txt', 'emb']\n",
      "translated 50 queries\n",
      "['data/hi/parsed/cord19.topics.question.hi2eng.emb_synset.txt', 'emb_synset']\n",
      "translated 50 queries\n",
      "['data/hi/parsed/cord19.topics.question.hi2eng.emb_no_oov.txt', 'emb_no_oov']\n",
      "translated 50 queries\n",
      "['data/hi/parsed/cord19.topics.questions.hi2eng.gt.emb.synset.translit.txt', 'gt_emb_synset_translit']\n",
      "translated 50 queries\n"
     ]
    }
   ],
   "source": [
    "# questions\n",
    "infile = files.cord19_topics_questions_HINDI\n",
    "outfiles = [[files.cord19_topics_questions_HIN2ENG_GT, \"gt\"], \n",
    "            [files.cord19_topics_questions_HIN2ENG_EMB, \"emb\"], [files.cord19_topics_questions_HIN2ENG_EMB_SYNSET, \"emb_synset\"],\n",
    "           [files.cord19_topics_questions_HIN2ENG_EMB_NO_OOV, \"emb_no_oov\"],\n",
    "           [files.cord19_topics_questions_HIN2ENG_GT_EMB_SYNSET_TRANSLIT, \"gt_emb_synset_translit\"]]\n",
    "\n",
    "for ofile in outfiles:\n",
    "    print(ofile)\n",
    "    convert_queries_from_src_to_dest_lang(infile, ofile[0], src=\"hi\", dest=\"en\", conv_type=ofile[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9c196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hi2en-clir)",
   "language": "python",
   "name": "hi2en-clir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
